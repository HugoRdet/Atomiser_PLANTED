{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e28fc5-b768-412c-8e0a-91aece41507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112e4cd70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training.perceiver import*\n",
    "from training.utils import*\n",
    "from training.losses import*\n",
    "from training.VIT import*\n",
    "from training.ResNet import*\n",
    "from collections import defaultdict\n",
    "from training import*\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import einops as einops\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Reduce\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cfe7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ids=get_ids_in_folder(base_path=\"./data/public/1.0.1/test/\")\n",
    "\n",
    "idx=10\n",
    "data=load_npz_by_id(idx,base_path=\"./data/public/1.0.1/test/\")\n",
    "\n",
    "\n",
    "\n",
    "#data=np.load(\"path\")\n",
    "tmp_name=data[\"alos\"][idx] #shape : 5000;4;4;4;3 (batch / time / h / w / c)\n",
    "print(tmp_name.shape)\n",
    "\n",
    "#3456\n",
    "#11520\n",
    "#1920\n",
    "#420\n",
    "#192\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c312fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataset(name=\"tiny\", mode=\"test\",max_imgs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca540407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f06a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "transconfig=transformations_config_flair(\"./data/bands_info/bands.yaml\",config)\n",
    "\n",
    "dataset=CustomPlanted(\"./data/custom_planted/tiny_train.h5\", config=config, trans_config=transconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd240e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.5973e-06, 8.2588e-02, 9.9997e-01,  ..., 8.8210e-01, 8.5286e-01,\n",
       "          4.3716e-02],\n",
       "         [1.5973e-06, 8.2588e-02, 9.9997e-01,  ..., 8.8210e-01, 8.5286e-01,\n",
       "          4.3716e-02],\n",
       "         [1.5973e-06, 8.2588e-02, 9.9997e-01,  ..., 8.8210e-01, 8.5286e-01,\n",
       "          4.3716e-02],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
       " np.int64(14),\n",
       " np.int64(0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hugoriffaud/Documents/PLANTED/checkpoints exists and is not empty.\n",
      "\n",
      "   | Name                      | Type                      | Params | Mode \n",
      "---------------------------------------------------------------------------------\n",
      "0  | metric_Acc_train          | MulticlassAccuracy        | 0      | train\n",
      "1  | metric_Acc_validation     | MulticlassAccuracy        | 0      | train\n",
      "2  | metric_Acc_test           | MulticlassAccuracy        | 0      | train\n",
      "3  | metric_F1_train           | MulticlassF1Score         | 0      | train\n",
      "4  | metric_F1_validation      | MulticlassF1Score         | 0      | train\n",
      "5  | metric_F1_test            | MulticlassF1Score         | 0      | train\n",
      "6  | metric_F1_train_freq      | MulticlassF1Score         | 0      | train\n",
      "7  | metric_F1_validation_freq | MulticlassF1Score         | 0      | train\n",
      "8  | metric_F1_test_freq       | MulticlassF1Score         | 0      | train\n",
      "9  | metric_F1_train_com       | MulticlassF1Score         | 0      | train\n",
      "10 | metric_F1_validation_com  | MulticlassF1Score         | 0      | train\n",
      "11 | metric_F1_test_com        | MulticlassF1Score         | 0      | train\n",
      "12 | metric_F1_train_rare      | MulticlassF1Score         | 0      | train\n",
      "13 | metric_F1_validation_rare | MulticlassF1Score         | 0      | train\n",
      "14 | metric_F1_test_rare       | MulticlassF1Score         | 0      | train\n",
      "15 | metric_IoU_val            | MulticlassJaccardIndex    | 0      | train\n",
      "16 | metric_IoU_test           | MulticlassJaccardIndex    | 0      | train\n",
      "17 | confmat_test              | MulticlassConfusionMatrix | 0      | train\n",
      "18 | encoder                   | Atomiser                  | 15.2 M | train\n",
      "19 | loss                      | CrossEntropyLoss          | 0      | train\n",
      "---------------------------------------------------------------------------------\n",
      "15.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.2 M    Total params\n",
      "60.611    Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]Validation DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created on rank: 0                                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassJaccardIndex was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassF1Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 132/1075701 [00:11<26:05:34, 11.45it/s, v_num=17]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import torch\n",
    "import os\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "config_model = read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "labels = load_json_to_dict(\"./data/labels.json\")\n",
    "bands_yaml = \"./data/bands_info/bands.yaml\"\n",
    "\n",
    "trans_config = transformations_config_flair(bands_yaml, config_model)\n",
    "xp_name = \"test_Atos\"\n",
    "\n",
    "wand = False\n",
    "wandb_logger = None\n",
    "if wand:\n",
    "    if os.environ.get(\"LOCAL_RANK\", \"0\") == \"0\":\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            name=get_xp_name(config_model['encoder']) + \" modalities\",\n",
    "            project=\"Atos_modalities\",\n",
    "            config=config_model\n",
    "        )\n",
    "        wandb_logger = WandbLogger(project=\"tiny_modalities\")\n",
    "\n",
    "model = Model(config_model, wand=wand, name=xp_name, labels=labels,transform=trans_config)\n",
    "\n",
    "data_module = CustomPlantedDataModule(\n",
    "    \"./data/custom_planted/tiny\",\n",
    "    config=config_model,\n",
    "    trans_config=trans_config,\n",
    "    batch_size=config_model['dataset']['batchsize'],\n",
    ")\n",
    "\n",
    "data_module.setup()\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./checkpoints/\",\n",
    "    filename=\"best_model-{epoch:02d}-{val_IoU:.4f}\",\n",
    "    monitor=\"val_IoU\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_IoU\",\n",
    "    min_delta=0.00,\n",
    "    patience=15,\n",
    "    verbose=False,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    use_distributed_sampler=False,\n",
    "    #strategy=\"ddp\",\n",
    "    #devices=-1,\n",
    "    max_epochs=config_model[\"trainer\"][\"epochs\"],\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    accelerator=\"gpu\",\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    default_root_dir=\"./checkpoints/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(model, datamodule=data_module)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
