{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e28fc5-b768-412c-8e0a-91aece41507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x111050d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training.perceiver import*\n",
    "from training.utils import*\n",
    "from training.losses import*\n",
    "from training.VIT import*\n",
    "from training.ResNet import*\n",
    "from collections import defaultdict\n",
    "from training import*\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import einops as einops\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Reduce\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3093e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_channel_mean_std(mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c312fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataset(name=\"tiny\", mode=\"train\",max_imgs=-1)\n",
    "#create_dataset(name=\"tiny\", mode=\"test\",max_imgs=-1)\n",
    "#create_dataset(name=\"tiny\", mode=\"validation\",max_imgs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f06a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "transconfig=transformations_config_flair(\"./data/bands_info/bands.yaml\",config)\n",
    "\n",
    "dataset=CustomPlanted(\"./data/custom_planted/tiny_train.h5\", config=config, trans_config=transconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hugoriffaud/Documents/PLANTED/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name                      | Type                         | Params | Mode \n",
      "-----------------------------------------------------------------------------------\n",
      "0 | transform                 | transformations_config_flair | 0      | train\n",
      "1 | metric_Acc_train          | MulticlassAccuracy           | 0      | train\n",
      "2 | metric_Acc_validation     | MulticlassAccuracy           | 0      | train\n",
      "3 | metric_Acc_test           | MulticlassAccuracy           | 0      | train\n",
      "4 | metric_F1_train_per_class | MulticlassF1Score            | 0      | train\n",
      "5 | metric_F1_val_per_class   | MulticlassF1Score            | 0      | train\n",
      "6 | metric_F1_test_per_class  | MulticlassF1Score            | 0      | train\n",
      "7 | confmat_test              | MulticlassConfusionMatrix    | 0      | train\n",
      "8 | encoder                   | ResNet                       | 8.1 M  | train\n",
      "9 | loss                      | CrossEntropyLoss             | 0      | train\n",
      "-----------------------------------------------------------------------------------\n",
      "8.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.1 M     Total params\n",
      "32.406    Total estimated model params size (MB)\n",
      "64        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]Validation DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 14 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created on rank: 0                                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:11<00:00,  0.17it/s, v_num=248]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 2: 'val_F1' reached 0.01667 (best 0.01667), saving model to '/Users/hugoriffaud/Documents/PLANTED/checkpoints/best_model-epoch=00-val_F1=0.0167-v3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:11<00:00,  0.17it/s, v_num=248]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import torch\n",
    "import os\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "config_model = read_yaml(\"./training/configs/config_test-ViT.yaml\")\n",
    "labels = load_json_to_dict(\"./data/labels.json\")\n",
    "bands_yaml = \"./data/bands_info/bands.yaml\"\n",
    "\n",
    "trans_config = transformations_config_flair(bands_yaml, config_model)\n",
    "xp_name = \"test_Atos\"\n",
    "\n",
    "wand = False\n",
    "wandb_logger = None\n",
    "if wand:\n",
    "    if os.environ.get(\"LOCAL_RANK\", \"0\") == \"0\":\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            name=get_xp_name(config_model['encoder']) + \" modalities\",\n",
    "            project=\"Atos_modalities\",\n",
    "            config=config_model\n",
    "        )\n",
    "        wandb_logger = WandbLogger(project=\"tiny_modalities\")\n",
    "\n",
    "model = Model(config_model, wand=wand, name=xp_name, labels=labels,transform=trans_config)\n",
    "\n",
    "data_module = CustomPlantedDataModule(\n",
    "    \"./data/custom_planted/tiny\",\n",
    "    config=config_model,\n",
    "    trans_config=trans_config,\n",
    "    batch_size=config_model['dataset']['batchsize'],\n",
    ")\n",
    "\n",
    "data_module.setup()\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./checkpoints/\",\n",
    "    filename=\"best_model-{epoch:02d}-{val_F1:.4f}\",\n",
    "    monitor=\"val_F1\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_F1\",\n",
    "    min_delta=0.00,\n",
    "    patience=15,\n",
    "    verbose=False,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    use_distributed_sampler=False,\n",
    "    #strategy=\"ddp\",\n",
    "    #devices=-1,\n",
    "    max_epochs=config_model[\"trainer\"][\"epochs\"],\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    accelerator=\"gpu\",\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    default_root_dir=\"./checkpoints/\",\n",
    "    limit_train_batches=2,\n",
    "    limit_val_batches=2\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655169ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244fb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
