{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e28fc5-b768-412c-8e0a-91aece41507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1168c4d70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training.perceiver import*\n",
    "from training.utils import*\n",
    "from training.losses import*\n",
    "from training.VIT import*\n",
    "from training.ResNet import*\n",
    "from collections import defaultdict\n",
    "from training import*\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import einops as einops\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Reduce\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cfe7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ids=get_ids_in_folder(base_path=\"./data/public/1.0.1/test/\")\n",
    "\n",
    "idx=10\n",
    "data=load_npz_by_id(idx,base_path=\"./data/public/1.0.1/test/\")\n",
    "\n",
    "\n",
    "\n",
    "#data=np.load(\"path\")\n",
    "tmp_name=data[\"alos\"][idx] #shape : 5000;4;4;4;3 (batch / time / h / w / c)\n",
    "print(tmp_name.shape)\n",
    "\n",
    "#3456\n",
    "#11520\n",
    "#1920\n",
    "#420\n",
    "#192\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3093e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_channel_mean_std(mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c312fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataset(name=\"tiny\", mode=\"train\",max_imgs=-1)\n",
    "#create_dataset(name=\"tiny\", mode=\"test\",max_imgs=-1)\n",
    "#create_dataset(name=\"tiny\", mode=\"validation\",max_imgs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f06a12",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "config=read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "transconfig=transformations_config_flair(\"./data/bands_info/bands.yaml\",config)\n",
    "\n",
    "dataset=CustomPlanted(\"./data/custom_planted/tiny_train.h5\", config=config, trans_config=transconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hugoriffaud/Documents/PLANTED/checkpoints exists and is not empty.\n",
      "\n",
      "   | Name                      | Type                      | Params | Mode \n",
      "---------------------------------------------------------------------------------\n",
      "0  | metric_Acc_train          | MulticlassAccuracy        | 0      | train\n",
      "1  | metric_Acc_validation     | MulticlassAccuracy        | 0      | train\n",
      "2  | metric_Acc_test           | MulticlassAccuracy        | 0      | train\n",
      "3  | metric_F1_train           | MulticlassF1Score         | 0      | train\n",
      "4  | metric_F1_validation      | MulticlassF1Score         | 0      | train\n",
      "5  | metric_F1_test            | MulticlassF1Score         | 0      | train\n",
      "6  | metric_F1_train_freq      | MulticlassF1Score         | 0      | train\n",
      "7  | metric_F1_validation_freq | MulticlassF1Score         | 0      | train\n",
      "8  | metric_F1_test_freq       | MulticlassF1Score         | 0      | train\n",
      "9  | metric_F1_train_com       | MulticlassF1Score         | 0      | train\n",
      "10 | metric_F1_validation_com  | MulticlassF1Score         | 0      | train\n",
      "11 | metric_F1_test_com        | MulticlassF1Score         | 0      | train\n",
      "12 | metric_F1_train_rare      | MulticlassF1Score         | 0      | train\n",
      "13 | metric_F1_validation_rare | MulticlassF1Score         | 0      | train\n",
      "14 | metric_F1_test_rare       | MulticlassF1Score         | 0      | train\n",
      "15 | confmat_test              | MulticlassConfusionMatrix | 0      | train\n",
      "16 | encoder                   | Atomiser                  | 15.1 M | train\n",
      "17 | loss                      | CrossEntropyLoss          | 0      | train\n",
      "---------------------------------------------------------------------------------\n",
      "15.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.1 M    Total params\n",
      "60.577    Total estimated model params size (MB)\n",
      "110       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9906, 1.3819, 0.0697, 0.1518, 0.5864, 0.7594, 0.2928, 0.4033, 1.2501,\n",
      "        1.6072, 0.8545, 0.6561, 0.5780, 0.2378, 0.4709, 1.0382, 0.6284, 1.7651,\n",
      "        1.9440, 1.4457, 4.0108, 3.9630, 1.6251, 6.4757, 3.4562, 3.9920, 2.8993,\n",
      "        3.7461, 3.1281, 5.1480, 4.7641, 4.0511, 4.3674, 5.6088, 5.5168, 7.2073,\n",
      "        5.7102, 6.4951, 6.4380, 7.7178])\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]Validation DataLoader created on rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 14 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]val loss tensor(3.5214, device='mps:0')\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  1.18it/s]val loss tensor(4.2152, device='mps:0')\n",
      "Train DataLoader created on rank: 0                                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassF1Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/hugoriffaud/Documents/PLANTED/venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 67/67 [00:58<00:00,  1.15it/s, v_num=215]val loss tensor(3.5719, device='mps:0')\n",
      "val loss tensor(3.6869, device='mps:0')\n",
      "val loss tensor(2.7660, device='mps:0')\n",
      "val loss tensor(3.9517, device='mps:0')\n",
      "val loss tensor(3.4278, device='mps:0')\n",
      "val loss tensor(3.1992, device='mps:0')\n",
      "val loss tensor(3.0934, device='mps:0')\n",
      "val loss tensor(3.7028, device='mps:0')\n",
      "Epoch 0: 100%|██████████| 67/67 [01:06<00:00,  1.01it/s, v_num=215]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 67: 'val_F1' reached 0.04236 (best 0.04236), saving model to '/Users/hugoriffaud/Documents/PLANTED/checkpoints/best_model-epoch=00-val_F1=0.0424.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 67/67 [00:59<00:00,  1.12it/s, v_num=215]val loss tensor(3.4220, device='mps:0')\n",
      "val loss tensor(3.1376, device='mps:0')\n",
      "val loss tensor(2.2025, device='mps:0')\n",
      "val loss tensor(3.6648, device='mps:0')\n",
      "val loss tensor(3.1156, device='mps:0')\n",
      "val loss tensor(3.0885, device='mps:0')\n",
      "val loss tensor(3.0866, device='mps:0')\n",
      "val loss tensor(3.4498, device='mps:0')\n",
      "Epoch 1: 100%|██████████| 67/67 [01:08<00:00,  0.98it/s, v_num=215]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 134: 'val_F1' reached 0.04851 (best 0.04851), saving model to '/Users/hugoriffaud/Documents/PLANTED/checkpoints/best_model-epoch=01-val_F1=0.0485.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 67/67 [00:59<00:00,  1.12it/s, v_num=215]val loss tensor(3.2432, device='mps:0')\n",
      "val loss tensor(2.9053, device='mps:0')\n",
      "val loss tensor(2.1151, device='mps:0')\n",
      "val loss tensor(3.3491, device='mps:0')\n",
      "val loss tensor(2.8889, device='mps:0')\n",
      "val loss tensor(2.9539, device='mps:0')\n",
      "val loss tensor(3.0744, device='mps:0')\n",
      "val loss tensor(3.1967, device='mps:0')\n",
      "Epoch 2: 100%|██████████| 67/67 [01:06<00:00,  1.01it/s, v_num=215]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 201: 'val_F1' reached 0.04884 (best 0.04884), saving model to '/Users/hugoriffaud/Documents/PLANTED/checkpoints/best_model-epoch=02-val_F1=0.0488.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   9%|▉         | 6/67 [00:11<01:57,  0.52it/s, v_num=215] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import torch\n",
    "import os\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "config_model = read_yaml(\"./training/configs/config_test-Atomiser_Atos.yaml\")\n",
    "labels = load_json_to_dict(\"./data/labels.json\")\n",
    "bands_yaml = \"./data/bands_info/bands.yaml\"\n",
    "\n",
    "trans_config = transformations_config_flair(bands_yaml, config_model)\n",
    "xp_name = \"test_Atos\"\n",
    "\n",
    "wand = False\n",
    "wandb_logger = None\n",
    "if wand:\n",
    "    if os.environ.get(\"LOCAL_RANK\", \"0\") == \"0\":\n",
    "        import wandb\n",
    "        wandb.init(\n",
    "            name=get_xp_name(config_model['encoder']) + \" modalities\",\n",
    "            project=\"Atos_modalities\",\n",
    "            config=config_model\n",
    "        )\n",
    "        wandb_logger = WandbLogger(project=\"tiny_modalities\")\n",
    "\n",
    "model = Model(config_model, wand=wand, name=xp_name, labels=labels,transform=trans_config)\n",
    "\n",
    "data_module = CustomPlantedDataModule(\n",
    "    \"./data/custom_planted/tiny\",\n",
    "    config=config_model,\n",
    "    trans_config=trans_config,\n",
    "    batch_size=config_model['dataset']['batchsize'],\n",
    ")\n",
    "\n",
    "data_module.setup()\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./checkpoints/\",\n",
    "    filename=\"best_model-{epoch:02d}-{val_F1:.4f}\",\n",
    "    monitor=\"val_F1\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_F1\",\n",
    "    min_delta=0.00,\n",
    "    patience=15,\n",
    "    verbose=False,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    use_distributed_sampler=False,\n",
    "    #strategy=\"ddp\",\n",
    "    #devices=-1,\n",
    "    max_epochs=config_model[\"trainer\"][\"epochs\"],\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    accelerator=\"gpu\",\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    default_root_dir=\"./checkpoints/\",\n",
    "    limit_train_batches=0.001,\n",
    "    limit_val_batches=0.001\n",
    ")\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "# Fit the model\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = SortKey.CUMULATIVE\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "print(s.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655169ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
